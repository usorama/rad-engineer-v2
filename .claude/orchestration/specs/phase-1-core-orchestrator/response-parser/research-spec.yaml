# Research Specification: ResponseParser
# Phase 1 - Core Orchestrator
#
# INSTRUCTIONS:
# 1. This spec defines research requirements for ResponseParser component
# 2. Execute 2 parallel research agents to gather evidence
# 3. All claims MUST have verified sources (no "I think", "probably", etc.)
# 4. After research, create component-spec.yaml and test-spec.yaml

metadata:
  component_name: "ResponseParser"
  phase: "Phase 1 - Core Orchestrator"
  version: "1.0.0"
  status: "research"
  created: "2026-01-05"
  researchers:
    - "Research Agent #1 (Response Patterns)"
    - "Research Agent #2 (Error Handling & Validation)"

research_questions:
  # Define 3-5 key questions that research must answer
  # Each question must be answerable with verified evidence

  - question_id: "RQ-001"
    question: "What are the expected response formats from agent execution?"
    priority: "critical"
    success_criteria: "Verified from CLAUDE.md structured output requirements"
    assigned_to: "Research Agent #1"

  - question_id: "RQ-002"
    question: "How do we parse JSON responses from agents reliably?"
    priority: "critical"
    success_criteria: "Verified from existing codebase and Node.js best practices"
    assigned_to: "Research Agent #1"

  - question_id: "RQ-003"
    question: "What error handling is required for malformed agent responses?"
    priority: "critical"
    success_criteria: "Verified from error handling patterns in codebase"
    assigned_to: "Research Agent #2"

  - question_id: "RQ-004"
    question: "How do we validate agent response structure and required fields?"
    priority: "high"
    success_criteria: "Verified from JSON validation best practices"
    assigned_to: "Research Agent #2"

  - question_id: "RQ-005"
    question: "How do we integrate ResponseParser with SDKIntegration and PromptValidator?"
    priority: "high"
    success_criteria: "Verified integration points from existing codebase"
    assigned_to: "Research Agent #2"

research_streams:
  # Define parallel research streams (max 2-3 agents)

  stream_1:
    agent_type: "research"
    focus: "Agent response format patterns and JSON parsing"
    questions:
      - "RQ-001"
      - "RQ-002"
    evidence_sources:
      - "CLAUDE.md structured output requirements"
      - "Existing codebase response patterns"
      - "Node.js JSON parsing best practices"
      - "Agent SDK response documentation"
    deliverable: "evidence/response-parser-formats.md"

  stream_2:
    agent_type: "research"
    focus: "Error handling and validation"
    questions:
      - "RQ-003"
      - "RQ-004"
      - "RQ-005"
    evidence_sources:
      - "Existing codebase error handling"
      - "JSON validation libraries (Zod, Ajv)"
      - "Error recovery patterns"
      - "Integration with SDKIntegration"
    deliverable: "evidence/response-parser-validation.md"

evidence_requirements:
  # Every claim must have one of these verification types

  verification_types:
    - type: "codebase_analysis"
      description: "Verified against existing code"
      confidence: "high"
      required_for: "integration point claims"

    - type: "primary_source"
      description: "Official documentation or API reference"
      confidence: "high"
      required_for: "all capability claims"

    - type: "measurement"
      description: "Actual system measurement or benchmark"
      confidence: "high"
      required_for: "all performance claims"

  claim_format: |
    For each claim, use this format:
    ```yaml
    claims:
      - id: "CLAIM-001"
        statement: "[Specific verifiable claim]"
        evidence_type: "[codebase_analysis|measurement|primary_source]"
        source: "[file path or URL]"
        verification_method: "[How to verify this claim]"
        confidence: "[high|medium|low]"
        required_for: "[component method or feature]"
    ```

prohibited_patterns:
  # NEVER use these patterns in research findings

  - pattern: "I think..."
    reason: "Speculation, not evidence"
    correction: "Find primary source or mark as unknown"

  - pattern: "It should work..."
    reason: "Unverified assumption"
    correction: "Test and document actual result"

  - pattern: "Probably..."
    reason: "Uncertainty without evidence"
    correction: "Verify or state 'unknown'"

  - pattern: "We can assume..."
    reason: "Assumptions lead to implementation gaps"
    correction: "Document as assumption, not claim"

output_format:
  research_findings:
    file: "evidence/research-findings.md"
    required_sections:
      - "## Evidence Summary"
      - "## Verified Claims (table format)"
      - "## Code Evidence (examples)"
      - "## References (all sources)"
      - "## Next Steps"

  claim_table_format: |
    | Claim ID | Capability | Status | Evidence Source | Verified By |

validation_criteria:
  research_complete_when:
    - "All research questions have answers with verified sources"
    - "All claims map to evidence IDs"
    - "Code examples provided for integration patterns"
    - "References section complete"
    - "No prohibited patterns present"
    - "Ready to generate component-spec.yaml"

next_steps:
  after_research:
    - step: "Create component-spec.yaml"
      uses: "research-findings.md"
      evidence_required: "All claims have evidence IDs"

    - step: "Create test-spec.yaml"
      uses: "component-spec.yaml"
      thresholds_from: "research-findings.md verified numbers"

    - step: "Validate specs"
      check: "All test requirements map to component methods"
      evidence_check: "All evidence IDs trace to research-findings.md"

---
# RESEARCH EXECUTION PLAN
#
# Research Agent #1 (Response Patterns):
# - Research structured output requirements from CLAUDE.md
# - Document expected JSON response format
# - Research JSON parsing patterns and error handling
# - Document integration with SDKIntegration response handling
#
# Research Agent #2 (Error Handling & Validation):
# - Research error handling for malformed responses
# - Document validation patterns for response structure
# - Research JSON validation libraries (Zod)
# - Document error recovery patterns
#
# Both agents return:
# - Structured findings with verified claims
# - Code examples for parsing patterns
# - References to all sources
