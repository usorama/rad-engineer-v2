# Research Specification: PromptValidator
# Phase 1 - Core Orchestrator
#
# INSTRUCTIONS:
# 1. This spec defines research requirements for PromptValidator component
# 2. Execute 2 parallel research agents to gather evidence
# 3. All claims MUST have verified sources (no "I think", "probably", etc.)
# 4. After research, create component-spec.yaml and test-spec.yaml

metadata:
  component_name: "PromptValidator"
  phase: "Phase 1 - Core Orchestrator"
  version: "1.0.0"
  status: "research"
  created: "2026-01-05"
  researchers:
    - "Research Agent #1 (Prompt Validation Rules)"
    - "Research Agent #2 (Security & Sanitization)"

research_questions:
  # Define 3-5 key questions that research must answer
  # Each question must be answerable with verified evidence

  - question_id: "RQ-001"
    question: "What are the prompt size limits for agent execution (max characters, tokens)?"
    priority: "critical"
    success_criteria: "Verified from Claude API documentation and existing codebase"
    assigned_to: "Research Agent #1"

  - question_id: "RQ-002"
    question: "What validation rules are required for agent prompts (format, structure, required fields)?"
    priority: "critical"
    success_criteria: "Verified from CLAUDE.md rules and SDK patterns"
    assigned_to: "Research Agent #1"

  - question_id: "RQ-003"
    question: "What security threats must be sanitized from prompts (injection, PII, dangerous commands)?"
    priority: "critical"
    success_criteria: "Verified from security best practices and OWASP guidelines"
    assigned_to: "Research Agent #2"

  - question_id: "RQ-004"
    question: "What sanitization techniques are effective for prompt content (escaping, filtering, redaction)?"
    priority: "high"
    success_criteria: "Verified from security documentation and Node.js best practices"
    assigned_to: "Research Agent #2"

  - question_id: "RQ-005"
    question: "How do we integrate PromptValidator with ResourceManager and SDKIntegration?"
    priority: "high"
    success_criteria: "Verified integration points from existing codebase"
    assigned_to: "Research Agent #2"

research_streams:
  # Define parallel research streams (max 2-3 agents)

  stream_1:
    agent_type: "research"
    focus: "Prompt validation rules and format checking"
    questions:
      - "RQ-001"
      - "RQ-002"
    evidence_sources:
      - "Existing codebase (CLAUDE.md rules, SDKIntegration.ts)"
      - "Claude API documentation"
      - "Agent SDK prompt patterns"
      - "Best practices for prompt validation"
    deliverable: "evidence/prompt-validator-rules.md"

  stream_2:
    agent_type: "research"
    focus: "Security and sanitization"
    questions:
      - "RQ-003"
      - "RQ-004"
      - "RQ-005"
    evidence_sources:
      - "OWASP Prompt Injection Guide"
      - "Security best practices for LLM applications"
      - "Node.js sanitization libraries"
      - "Existing codebase security patterns"
    deliverable: "evidence/prompt-validator-security.md"

evidence_requirements:
  # Every claim must have one of these verification types

  verification_types:
    - type: "codebase_analysis"
      description: "Verified against existing code"
      confidence: "high"
      required_for: "integration point claims"

    - type: "measurement"
      description: "Actual system measurement or benchmark"
      confidence: "high"
      required_for: "all performance claims"

    - type: "primary_source"
      description: "Official documentation or API reference"
      confidence: "high"
      required_for: "all capability claims"

  claim_format: |
    For each claim, use this format:
    ```yaml
    claims:
      - id: "CLAIM-001"
        statement: "[Specific verifiable claim]"
        evidence_type: "[codebase_analysis|measurement|primary_source]"
        source: "[file path or URL]"
        verification_method: "[How to verify this claim]"
        confidence: "[high|medium|low]"
        required_for: "[component method or feature]"
    ```

prohibited_patterns:
  # NEVER use these patterns in research findings

  - pattern: "I think..."
    reason: "Speculation, not evidence"
    correction: "Find primary source or mark as unknown"

  - pattern: "It should work..."
    reason: "Unverified assumption"
    correction: "Test and document actual result"

  - pattern: "Probably..."
    reason: "Uncertainty without evidence"
    correction: "Verify or state 'unknown'"

  - pattern: "We can assume..."
    reason: "Assumptions lead to implementation gaps"
    correction: "Document as assumption, not claim"

output_format:
  research_findings:
    file: "evidence/research-findings.md"
    required_sections:
      - "## Evidence Summary"
      - "## Verified Claims (table format)"
      - "## Code Evidence (examples)"
      - "## References (all sources)"
      - "## Next Steps"

  claim_table_format: |
    | Claim ID | Capability | Status | Evidence Source | Verified By |

validation_criteria:
  research_complete_when:
    - "All research questions have answers with verified sources"
    - "All claims map to evidence IDs"
    - "Code examples provided for integration patterns"
    - "References section complete"
    - "No prohibited patterns present"
    - "Ready to generate component-spec.yaml"

next_steps:
  after_research:
    - step: "Create component-spec.yaml"
      uses: "research-findings.md"
      evidence_required: "All claims have evidence IDs"

    - step: "Create test-spec.yaml"
      uses: "component-spec.yaml"
      thresholds_from: "research-findings.md verified numbers"

    - step: "Validate specs"
      check: "All test requirements map to component methods"
      evidence_check: "All evidence IDs trace to research-findings.md"

---
# RESEARCH EXECUTION PLAN
#
# Research Agent #1 (Prompt Validation Rules):
# - Research prompt size limits from Claude API docs
# - Document validation rules from CLAUDE.md
# - Research format checking patterns
# - Document integration with ResourceManager
#
# Research Agent #2 (Security & Sanitization):
# - Research prompt injection threats (OWASP)
# - Document sanitization techniques
# - Research PII redaction patterns
# - Document integration with SDKIntegration
#
# Both agents return:
# - Structured findings with verified claims
# - Code examples for validation patterns
# - References to all sources
