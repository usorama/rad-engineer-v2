#!/usr/bin/env python3
"""
Risk Classifier Module
======================

Reads the AI-generated complexity_assessment.json and provides programmatic
access to risk classification and validation recommendations.

This module serves as the bridge between the AI complexity assessor prompt
and the rest of the validation system.

Usage:
    from risk_classifier import RiskClassifier

    classifier = RiskClassifier()
    assessment = classifier.load_assessment(spec_dir)

    if classifier.should_skip_validation(spec_dir):
        print("Validation can be skipped for this task")

    test_types = classifier.get_required_test_types(spec_dir)
"""

from __future__ import annotations

import json
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any

# =============================================================================
# DATA CLASSES
# =============================================================================


@dataclass
class ScopeAnalysis:
    """Analysis of task scope."""

    estimated_files: int = 0
    estimated_services: int = 0
    is_cross_cutting: bool = False
    notes: str = ""


@dataclass
class IntegrationAnalysis:
    """Analysis of external integrations."""

    external_services: list[str] = field(default_factory=list)
    new_dependencies: list[str] = field(default_factory=list)
    research_needed: bool = False
    notes: str = ""


@dataclass
class InfrastructureAnalysis:
    """Analysis of infrastructure requirements."""

    docker_changes: bool = False
    database_changes: bool = False
    config_changes: bool = False
    notes: str = ""


@dataclass
class KnowledgeAnalysis:
    """Analysis of knowledge requirements."""

    patterns_exist: bool = True
    research_required: bool = False
    unfamiliar_tech: list[str] = field(default_factory=list)
    notes: str = ""


@dataclass
class RiskAnalysis:
    """Analysis of task risk."""

    level: str = "low"  # low, medium, high
    concerns: list[str] = field(default_factory=list)
    notes: str = ""


@dataclass
class ComplexityAnalysis:
    """Full complexity analysis from the AI assessor."""

    scope: ScopeAnalysis = field(default_factory=ScopeAnalysis)
    integrations: IntegrationAnalysis = field(default_factory=IntegrationAnalysis)
    infrastructure: InfrastructureAnalysis = field(
        default_factory=InfrastructureAnalysis
    )
    knowledge: KnowledgeAnalysis = field(default_factory=KnowledgeAnalysis)
    risk: RiskAnalysis = field(default_factory=RiskAnalysis)


@dataclass
class ValidationRecommendations:
    """Validation recommendations from the AI assessor."""

    risk_level: str = "medium"  # trivial, low, medium, high, critical
    skip_validation: bool = False
    minimal_mode: bool = False
    test_types_required: list[str] = field(default_factory=lambda: ["unit"])
    security_scan_required: bool = False
    staging_deployment_required: bool = False
    reasoning: str = ""


@dataclass
class AssessmentFlags:
    """Flags indicating special requirements."""

    needs_research: bool = False
    needs_self_critique: bool = False
    needs_infrastructure_setup: bool = False


@dataclass
class RiskAssessment:
    """Complete risk assessment from complexity_assessment.json."""

    complexity: str  # simple, standard, complex
    workflow_type: str  # feature, refactor, investigation, migration, simple
    confidence: float
    reasoning: str
    analysis: ComplexityAnalysis
    recommended_phases: list[str]
    flags: AssessmentFlags
    validation: ValidationRecommendations
    created_at: str | None = None

    @property
    def risk_level(self) -> str:
        """Get the risk level from validation recommendations."""
        return self.validation.risk_level


# =============================================================================
# RISK CLASSIFIER
# =============================================================================


class RiskClassifier:
    """
    Reads AI-generated complexity_assessment.json and provides risk classification.

    The complexity_assessment.json is generated by the AI complexity assessor
    agent using the complexity_assessor.md prompt. This module parses that output
    and provides programmatic access to the risk classification.
    """

    def __init__(self) -> None:
        """Initialize the risk classifier."""
        self._cache: dict[str, RiskAssessment] = {}

    def load_assessment(self, spec_dir: Path) -> RiskAssessment | None:
        """
        Load complexity_assessment.json from spec directory.

        Args:
            spec_dir: Path to the spec directory containing complexity_assessment.json

        Returns:
            RiskAssessment object if file exists and is valid, None otherwise
        """
        spec_dir = Path(spec_dir)
        cache_key = str(spec_dir.resolve())

        # Return cached result if available
        if cache_key in self._cache:
            return self._cache[cache_key]

        assessment_file = spec_dir / "complexity_assessment.json"
        if not assessment_file.exists():
            return None

        try:
            with open(assessment_file, encoding="utf-8") as f:
                data = json.load(f)

            assessment = self._parse_assessment(data)
            self._cache[cache_key] = assessment
            return assessment

        except (json.JSONDecodeError, KeyError, TypeError) as e:
            # Log error but don't crash - return None to allow fallback behavior
            print(f"Warning: Failed to parse complexity_assessment.json: {e}")
            return None

    def _parse_assessment(self, data: dict[str, Any]) -> RiskAssessment:
        """Parse raw JSON data into a RiskAssessment object."""
        # Parse analysis sections
        analysis_data = data.get("analysis", {})
        analysis = ComplexityAnalysis(
            scope=self._parse_scope(analysis_data.get("scope", {})),
            integrations=self._parse_integrations(
                analysis_data.get("integrations", {})
            ),
            infrastructure=self._parse_infrastructure(
                analysis_data.get("infrastructure", {})
            ),
            knowledge=self._parse_knowledge(analysis_data.get("knowledge", {})),
            risk=self._parse_risk(analysis_data.get("risk", {})),
        )

        # Parse flags
        flags_data = data.get("flags", {})
        flags = AssessmentFlags(
            needs_research=flags_data.get("needs_research", False),
            needs_self_critique=flags_data.get("needs_self_critique", False),
            needs_infrastructure_setup=flags_data.get(
                "needs_infrastructure_setup", False
            ),
        )

        # Parse validation recommendations
        validation_data = data.get("validation_recommendations", {})
        validation = self._parse_validation_recommendations(validation_data, analysis)

        return RiskAssessment(
            complexity=data.get("complexity", "standard"),
            workflow_type=data.get("workflow_type", "feature"),
            confidence=float(data.get("confidence", 0.5)),
            reasoning=data.get("reasoning", ""),
            analysis=analysis,
            recommended_phases=data.get("recommended_phases", []),
            flags=flags,
            validation=validation,
            created_at=data.get("created_at"),
        )

    def _parse_scope(self, data: dict[str, Any]) -> ScopeAnalysis:
        """Parse scope analysis section."""
        return ScopeAnalysis(
            estimated_files=int(data.get("estimated_files", 0)),
            estimated_services=int(data.get("estimated_services", 0)),
            is_cross_cutting=bool(data.get("is_cross_cutting", False)),
            notes=str(data.get("notes", "")),
        )

    def _parse_integrations(self, data: dict[str, Any]) -> IntegrationAnalysis:
        """Parse integrations analysis section."""
        return IntegrationAnalysis(
            external_services=list(data.get("external_services", [])),
            new_dependencies=list(data.get("new_dependencies", [])),
            research_needed=bool(data.get("research_needed", False)),
            notes=str(data.get("notes", "")),
        )

    def _parse_infrastructure(self, data: dict[str, Any]) -> InfrastructureAnalysis:
        """Parse infrastructure analysis section."""
        return InfrastructureAnalysis(
            docker_changes=bool(data.get("docker_changes", False)),
            database_changes=bool(data.get("database_changes", False)),
            config_changes=bool(data.get("config_changes", False)),
            notes=str(data.get("notes", "")),
        )

    def _parse_knowledge(self, data: dict[str, Any]) -> KnowledgeAnalysis:
        """Parse knowledge analysis section."""
        return KnowledgeAnalysis(
            patterns_exist=bool(data.get("patterns_exist", True)),
            research_required=bool(data.get("research_required", False)),
            unfamiliar_tech=list(data.get("unfamiliar_tech", [])),
            notes=str(data.get("notes", "")),
        )

    def _parse_risk(self, data: dict[str, Any]) -> RiskAnalysis:
        """Parse risk analysis section."""
        return RiskAnalysis(
            level=str(data.get("level", "low")),
            concerns=list(data.get("concerns", [])),
            notes=str(data.get("notes", "")),
        )

    def _parse_validation_recommendations(
        self, data: dict[str, Any], analysis: ComplexityAnalysis
    ) -> ValidationRecommendations:
        """
        Parse validation recommendations section.

        If validation_recommendations is not present in the JSON (older assessments),
        infer appropriate values from the analysis.
        """
        if data:
            # New format with explicit validation recommendations
            return ValidationRecommendations(
                risk_level=str(data.get("risk_level", "medium")),
                skip_validation=bool(data.get("skip_validation", False)),
                minimal_mode=bool(data.get("minimal_mode", False)),
                test_types_required=list(data.get("test_types_required", ["unit"])),
                security_scan_required=bool(data.get("security_scan_required", False)),
                staging_deployment_required=bool(
                    data.get("staging_deployment_required", False)
                ),
                reasoning=str(data.get("reasoning", "")),
            )
        else:
            # Infer from analysis (backward compatibility)
            return self._infer_validation_recommendations(analysis)

    def _infer_validation_recommendations(
        self, analysis: ComplexityAnalysis
    ) -> ValidationRecommendations:
        """
        Infer validation recommendations from analysis when not explicitly provided.

        This provides backward compatibility with older complexity assessments
        that don't have the validation_recommendations section.
        """
        risk_level = analysis.risk.level

        # Map old risk levels to new ones
        risk_mapping = {
            "low": "low",
            "medium": "medium",
            "high": "high",
        }
        normalized_risk = risk_mapping.get(risk_level, "medium")

        # Infer test types based on risk
        test_types_map = {
            "low": ["unit"],
            "medium": ["unit", "integration"],
            "high": ["unit", "integration", "e2e"],
        }
        test_types = test_types_map.get(normalized_risk, ["unit", "integration"])

        # Security scan for high risk or security-related concerns
        security_keywords = [
            "security",
            "auth",
            "password",
            "credential",
            "token",
            "api key",
        ]
        has_security_concerns = any(
            kw in str(analysis.risk.concerns).lower() for kw in security_keywords
        )
        security_scan_required = normalized_risk == "high" or has_security_concerns

        # Staging for database or infrastructure changes
        staging_required = (
            analysis.infrastructure.database_changes
            and normalized_risk in ["medium", "high"]
        )

        # Minimal mode for simple changes
        minimal_mode = (
            analysis.scope.estimated_files <= 2
            and analysis.scope.estimated_services <= 1
            and not analysis.integrations.external_services
        )

        return ValidationRecommendations(
            risk_level=normalized_risk,
            skip_validation=False,  # Never skip by inference
            minimal_mode=minimal_mode,
            test_types_required=test_types,
            security_scan_required=security_scan_required,
            staging_deployment_required=staging_required,
            reasoning="Inferred from complexity analysis (no explicit recommendations found)",
        )

    def should_skip_validation(self, spec_dir: Path) -> bool:
        """
        Quick check if validation can be skipped entirely.

        Args:
            spec_dir: Path to the spec directory

        Returns:
            True if validation can be skipped (trivial changes), False otherwise
        """
        assessment = self.load_assessment(spec_dir)
        if not assessment:
            return False  # When in doubt, don't skip

        return assessment.validation.skip_validation

    def should_use_minimal_mode(self, spec_dir: Path) -> bool:
        """
        Check if minimal validation mode should be used.

        Args:
            spec_dir: Path to the spec directory

        Returns:
            True if minimal mode is recommended, False otherwise
        """
        assessment = self.load_assessment(spec_dir)
        if not assessment:
            return False

        return assessment.validation.minimal_mode

    def get_required_test_types(self, spec_dir: Path) -> list[str]:
        """
        Get list of required test types based on risk.

        Args:
            spec_dir: Path to the spec directory

        Returns:
            List of test types (e.g., ["unit", "integration", "e2e"])
        """
        assessment = self.load_assessment(spec_dir)
        if not assessment:
            return ["unit"]  # Default to unit tests

        return assessment.validation.test_types_required

    def requires_security_scan(self, spec_dir: Path) -> bool:
        """
        Check if security scanning is required.

        Args:
            spec_dir: Path to the spec directory

        Returns:
            True if security scan is required, False otherwise
        """
        assessment = self.load_assessment(spec_dir)
        if not assessment:
            return False

        return assessment.validation.security_scan_required

    def requires_staging_deployment(self, spec_dir: Path) -> bool:
        """
        Check if staging deployment is required.

        Args:
            spec_dir: Path to the spec directory

        Returns:
            True if staging deployment is required, False otherwise
        """
        assessment = self.load_assessment(spec_dir)
        if not assessment:
            return False

        return assessment.validation.staging_deployment_required

    def get_risk_level(self, spec_dir: Path) -> str:
        """
        Get the risk level for the task.

        Args:
            spec_dir: Path to the spec directory

        Returns:
            Risk level string (trivial, low, medium, high, critical)
        """
        assessment = self.load_assessment(spec_dir)
        if not assessment:
            return "medium"  # Default to medium when unknown

        return assessment.validation.risk_level

    def get_complexity(self, spec_dir: Path) -> str:
        """
        Get the complexity level for the task.

        Args:
            spec_dir: Path to the spec directory

        Returns:
            Complexity level string (simple, standard, complex)
        """
        assessment = self.load_assessment(spec_dir)
        if not assessment:
            return "standard"  # Default to standard when unknown

        return assessment.complexity

    def get_validation_summary(self, spec_dir: Path) -> dict[str, Any]:
        """
        Get a summary of validation requirements.

        Args:
            spec_dir: Path to the spec directory

        Returns:
            Dictionary with validation summary
        """
        assessment = self.load_assessment(spec_dir)
        if not assessment:
            return {
                "risk_level": "unknown",
                "complexity": "unknown",
                "skip_validation": False,
                "minimal_mode": False,
                "test_types": ["unit"],
                "security_scan": False,
                "staging_deployment": False,
                "confidence": 0.0,
            }

        return {
            "risk_level": assessment.validation.risk_level,
            "complexity": assessment.complexity,
            "skip_validation": assessment.validation.skip_validation,
            "minimal_mode": assessment.validation.minimal_mode,
            "test_types": assessment.validation.test_types_required,
            "security_scan": assessment.validation.security_scan_required,
            "staging_deployment": assessment.validation.staging_deployment_required,
            "confidence": assessment.confidence,
            "reasoning": assessment.validation.reasoning,
        }

    def clear_cache(self) -> None:
        """Clear the internal cache of loaded assessments."""
        self._cache.clear()


# =============================================================================
# CONVENIENCE FUNCTIONS
# =============================================================================


def load_risk_assessment(spec_dir: Path) -> RiskAssessment | None:
    """
    Convenience function to load a risk assessment.

    Args:
        spec_dir: Path to the spec directory

    Returns:
        RiskAssessment object or None
    """
    classifier = RiskClassifier()
    return classifier.load_assessment(spec_dir)


def get_validation_requirements(spec_dir: Path) -> dict[str, Any]:
    """
    Convenience function to get validation requirements.

    Args:
        spec_dir: Path to the spec directory

    Returns:
        Dictionary with validation requirements
    """
    classifier = RiskClassifier()
    return classifier.get_validation_summary(spec_dir)


# =============================================================================
# CLI
# =============================================================================


def main() -> None:
    """CLI entry point for testing."""
    import argparse

    parser = argparse.ArgumentParser(description="Load and display risk assessment")
    parser.add_argument(
        "spec_dir",
        type=Path,
        help="Path to spec directory with complexity_assessment.json",
    )
    parser.add_argument("--json", action="store_true", help="Output as JSON")

    args = parser.parse_args()

    classifier = RiskClassifier()
    summary = classifier.get_validation_summary(args.spec_dir)

    if args.json:
        print(json.dumps(summary, indent=2))
    else:
        print(f"Risk Level: {summary['risk_level']}")
        print(f"Complexity: {summary['complexity']}")
        print(f"Skip Validation: {summary['skip_validation']}")
        print(f"Minimal Mode: {summary['minimal_mode']}")
        print(f"Test Types: {', '.join(summary['test_types'])}")
        print(f"Security Scan: {summary['security_scan']}")
        print(f"Staging Deployment: {summary['staging_deployment']}")
        print(f"Confidence: {summary['confidence']:.2f}")
        if summary.get("reasoning"):
            print(f"Reasoning: {summary['reasoning']}")


if __name__ == "__main__":
    main()
